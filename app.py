import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import time
import io
import os
import sys
import tempfile
import mimetypes
import magic

# ==============================================================================
# Streamlit åº”ç”¨ç•Œé¢
# ==============================================================================

st.set_page_config(page_title="Hedge Master Analytics", page_icon="ğŸ“ˆ", layout="wide")

# CSS æ ·å¼
st.markdown("""
<style>
    .stDataFrame { 
        border: 1px solid #ddd; 
        border-radius: 5px; 
        font-size: 14px;
    }
    .metric-card { 
        background-color: #f8f9fa; 
        padding: 15px; 
        border-radius: 8px; 
        margin-bottom: 10px;
        border-left: 4px solid #4e73df;
    }
    .header-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 20px;
        border-radius: 10px;
        color: white;
        margin-bottom: 20px;
    }
    .success-message {
        background-color: #d4edda;
        border-color: #c3e6cb;
        color: #155724;
        padding: 15px;
        border-radius: 5px;
        margin: 10px 0;
    }
    .warning-message {
        background-color: #fff3cd;
        border-color: #ffeaa7;
        color: #856404;
        padding: 15px;
        border-radius: 5px;
        margin: 10px 0;
    }
    .error-message {
        background-color: #f8d7da;
        border-color: #f5c6cb;
        color: #721c24;
        padding: 15px;
        border-radius: 5px;
        margin: 10px 0;
    }
</style>
""", unsafe_allow_html=True)

# æ ‡é¢˜åŒºåŸŸ
st.markdown('<div class="header-card">', unsafe_allow_html=True)
st.title("ğŸ›¡ï¸ Hedge Master Analytics")
st.markdown("**åŸºäº v19 å¼•æ“çš„æ™ºèƒ½å¥—ä¿æœ‰æ•ˆæ€§åˆ†æç³»ç»Ÿ**")
st.caption("Version: 2.0 | æ”¯æŒå¼€æ”¾å¼æ—¶é—´åŒ¹é…ç®—æ³•")
st.markdown('</div>', unsafe_allow_html=True)

# ==============================================================================
# ä¿®å¤çš„æ–‡ä»¶è¯»å–å‡½æ•°
# ==============================================================================

def detect_file_type(file_content, file_name):
    """æ£€æµ‹æ–‡ä»¶çš„çœŸå®ç±»å‹"""
    # é¦–å…ˆæ ¹æ®æ–‡ä»¶å†…å®¹ç‰¹å¾åˆ¤æ–­
    try:
        # å°è¯•æ£€æµ‹Excelæ–‡ä»¶ç‰¹å¾
        if file_content[:8] == b'\x50\x4b\x03\x04':  # ZIP header (Excelæ˜¯ZIPæ–‡ä»¶)
            return 'excel'
        elif file_content[:4] == b'\xd0\xcf\x11\xe0':  # OLE header (æ—§ç‰ˆExcel)
            return 'excel'
        elif b'<worksheet' in file_content[:1000] or b'<Workbook' in file_content[:1000]:
            return 'excel'
    except:
        pass
    
    # ç„¶åå°è¯•æ ¹æ®æ‰©å±•ååˆ¤æ–­
    file_name_lower = file_name.lower()
    if file_name_lower.endswith(('.xlsx', '.xls')):
        return 'excel'
    elif file_name_lower.endswith('.csv'):
        return 'csv'
    
    # æœ€åæ ¹æ®å†…å®¹ç‰¹å¾åˆ¤æ–­CSV
    try:
        # æ£€æŸ¥æ˜¯å¦åŒ…å«é€—å·åˆ†éš”ç¬¦
        sample = file_content[:1000].decode('utf-8', errors='ignore')
        if ',' in sample or ';' in sample:
            return 'csv'
    except:
        pass
    
    return 'unknown'

def read_file_with_correct_type(file_content, file_name):
    """ä½¿ç”¨æ­£ç¡®çš„ç±»å‹è¯»å–æ–‡ä»¶"""
    file_type = detect_file_type(file_content, file_name)
    
    if file_type == 'excel':
        try:
            return pd.read_excel(io.BytesIO(file_content))
        except Exception as e:
            st.warning(f"Excelè¯»å–å¤±è´¥ï¼Œå°è¯•å…¶ä»–æ–¹æ³•: {e}")
            # å°è¯•è¯»å–ç¬¬ä¸€ä¸ªsheet
            try:
                return pd.read_excel(io.BytesIO(file_content), sheet_name=0)
            except:
                # å°è¯•ä½¿ç”¨openpyxlå¼•æ“
                try:
                    return pd.read_excel(io.BytesIO(file_content), engine='openpyxl')
                except:
                    raise ValueError(f"æ— æ³•è¯»å–Excelæ–‡ä»¶: {file_name}")
    
    elif file_type == 'csv':
        encodings = ['utf-8', 'utf-8-sig', 'gbk', 'gb18030', 'latin1', 'iso-8859-1', 'cp1252']
        
        for enc in encodings:
            try:
                return pd.read_csv(io.BytesIO(file_content), encoding=enc)
            except Exception:
                continue
        
        # å¦‚æœæ‰€æœ‰ç¼–ç éƒ½å¤±è´¥ï¼Œå°è¯•è‡ªåŠ¨æ£€æµ‹
        try:
            import chardet
            result = chardet.detect(file_content)
            return pd.read_csv(io.BytesIO(file_content), encoding=result['encoding'])
        except ImportError:
            # æœ€åçš„æ‰‹æ®µ
            try:
                return pd.read_csv(io.BytesIO(file_content), encoding='utf-8', errors='ignore')
            except Exception as e:
                raise ValueError(f"æ— æ³•è¯»å–CSVæ–‡ä»¶: {e}")
        except Exception as e:
            raise ValueError(f"æ— æ³•è¯»å–CSVæ–‡ä»¶: {e}")
    
    else:
        raise ValueError(f"æ— æ³•è¯†åˆ«çš„æ–‡ä»¶ç±»å‹: {file_name}")

def save_file_with_correct_extension(file_content, file_name, temp_dir):
    """æ ¹æ®æ–‡ä»¶ç±»å‹ä¿å­˜ä¸ºæ­£ç¡®æ‰©å±•åçš„æ–‡ä»¶"""
    file_type = detect_file_type(file_content, file_name)
    
    if file_type == 'excel':
        ext = '.xlsx' if file_name.lower().endswith('.xlsx') else '.xls'
        temp_path = os.path.join(temp_dir, f"paper_data{ext}")
    else:
        temp_path = os.path.join(temp_dir, "paper_data.csv")
    
    with open(temp_path, "wb") as f:
        f.write(file_content)
    
    return temp_path

# ==============================================================================
# ä¿®å¤çš„å¼•æ“åŒ…è£…å‡½æ•°
# ==============================================================================

def run_hedge_engine_directly(paper_content, paper_name, phys_content, phys_name):
    """ç›´æ¥è¿è¡Œå¯¹å†²å¼•æ“"""
    # åˆ›å»ºä¸´æ—¶ç›®å½•
    temp_dir = tempfile.mkdtemp()
    
    try:
        # ä¿å­˜æ–‡ä»¶ï¼ˆä½¿ç”¨æ­£ç¡®çš„æ‰©å±•åï¼‰
        paper_path = save_file_with_correct_extension(paper_content, paper_name, temp_dir)
        phys_path = save_file_with_correct_extension(phys_content, phys_name, temp_dir)
        
        # å¯¼å…¥å¼•æ“
        sys.path.append(os.path.dirname(__file__))
        import hedge_engine as engine
        
        # æ‰‹åŠ¨è¯»å–æ•°æ®ï¼ˆç»•è¿‡å¼•æ“çš„æ–‡ä»¶è¯»å–ï¼‰
        df_paper = read_file_with_correct_type(paper_content, paper_name)
        df_physical = read_file_with_correct_type(phys_content, phys_name)
        
        # é¢„å¤„ç†æ•°æ®ä»¥åŒ¹é…å¼•æ“çš„æ ¼å¼
        # çº¸è´§æ•°æ®é¢„å¤„ç†
        if 'Trade Date' in df_paper.columns:
            df_paper['Trade Date'] = pd.to_datetime(df_paper['Trade Date'], errors='coerce')
        
        df_paper['Volume'] = pd.to_numeric(df_paper['Volume'], errors='coerce').fillna(0)
        
        if 'Commodity' in df_paper.columns:
            df_paper['Std_Commodity'] = df_paper['Commodity'].astype(str).str.strip().str.upper().replace('NAN', '')
        elif 'Std_Commodity' in df_paper.columns:
            df_paper['Std_Commodity'] = df_paper['Std_Commodity'].astype(str).str.strip().str.upper().replace('NAN', '')
        
        # æœˆä»½æ ‡å‡†åŒ–
        if 'Month' in df_paper.columns:
            df_paper['Month'] = engine.standardize_month_vectorized(df_paper['Month'])
        else:
            df_paper['Month'] = ''
        
        # Recap No è‹¥ä¸å­˜åœ¨åˆ™ç”¨ç´¢å¼•ä»£æ›¿
        if 'Recap No' not in df_paper.columns:
            df_paper['Recap No'] = df_paper.index.astype(str)
        
        df_paper['_original_index'] = df_paper.index
        
        # åˆå§‹åŒ–ç¼ºå¤±é‡‘èå­—æ®µ
        for col in ['Price', 'Mtm Price', 'Total P/L']:
            if col not in df_paper.columns:
                df_paper[col] = 0
        
        # å®è´§æ•°æ®é¢„å¤„ç†
        col_map = {'Target_Pricing_Month': 'Target_Contract_Month', 'Month': 'Target_Contract_Month'}
        df_physical.rename(columns=col_map, inplace=True)
        
        df_physical['Volume'] = pd.to_numeric(df_physical['Volume'], errors='coerce').fillna(0)
        df_physical['Unhedged_Volume'] = df_physical['Volume']
        
        if 'Hedge_Proxy' in df_physical.columns:
            df_physical['Hedge_Proxy'] = df_physical['Hedge_Proxy'].astype(str).str.strip().str.upper().replace('NAN', '')
        else:
            df_physical['Hedge_Proxy'] = ''
        
        # åˆçº¦æœˆæ ‡å‡†åŒ–
        if 'Target_Contract_Month' in df_physical.columns:
            df_physical['Target_Contract_Month'] = engine.standardize_month_vectorized(df_physical['Target_Contract_Month'])
        
        # æŒ‡å®šæ—¥æœŸ
        date_cols = ['Designation_Date', 'Pricing_Start', 'Trade_Date']
        date_col_found = None
        for col in date_cols:
            if col in df_physical.columns:
                date_col_found = col
                break
        
        if date_col_found:
            df_physical['Designation_Date'] = pd.to_datetime(df_physical[date_col_found], errors='coerce')
        else:
            df_physical['Designation_Date'] = pd.NaT
        
        # è¿è¡Œå¼•æ“æ ¸å¿ƒå‡½æ•°
        if not df_physical.empty:
            # å…ˆå†…éƒ¨å‡€é¢åŒ–çº¸è´§
            df_paper_net = engine.calculate_net_positions_corrected(df_paper)
            
            # å®è´§åŒ¹é…
            df_rels, df_physical_updated = engine.auto_match_hedges(df_physical, df_paper_net)
            
            # è®¡ç®—çº¸è´§åˆ†é…æƒ…å†µ
            df_paper_final = df_paper_net.copy()
            if 'Allocated_To_Phy' not in df_paper_final.columns:
                df_paper_final['Allocated_To_Phy'] = 0
            
            if not df_rels.empty and 'Ticket_ID' in df_rels.columns:
                # æ±‡æ€»åˆ†é…é‡
                alloc_summary = df_rels.groupby('Ticket_ID')['Allocated_Vol'].sum().reset_index()
                alloc_summary.rename(columns={'Allocated_Vol': 'Allocated_To_Phy'}, inplace=True)
                
                # åˆå¹¶åˆ†é…é‡åˆ°çº¸è´§æ•°æ®
                if 'Recap No' in df_paper_final.columns:
                    df_paper_final = pd.merge(
                        df_paper_final, 
                        alloc_summary, 
                        left_on='Recap No', 
                        right_on='Ticket_ID', 
                        how='left'
                    )
                    df_paper_final['Allocated_To_Phy'] = df_paper_final['Allocated_To_Phy'].fillna(0)
                    
                    # æ¸…ç†ä¸´æ—¶åˆ—
                    if 'Ticket_ID' in df_paper_final.columns:
                        df_paper_final = df_paper_final.drop(columns=['Ticket_ID'])
            
            return df_rels, df_physical_updated, df_paper_final
        else:
            return pd.DataFrame(), df_physical, df_paper
            
    except Exception as e:
        raise e
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        import shutil
        try:
            shutil.rmtree(temp_dir)
        except:
            pass

# ==============================================================================
# ä¾§è¾¹æ 
# ==============================================================================

with st.sidebar:
    st.header("ğŸ“‚ æ•°æ®æ¥å…¥")
    
    col1, col2 = st.columns(2)
    with col1:
        st.metric("å¼•æ“çŠ¶æ€", "å°±ç»ª", "âœ“")
    with col2:
        st.metric("ç‰ˆæœ¬", "v19", "")
    
    st.markdown("---")
    
    ticket_file = st.file_uploader(
        "ğŸ“„ ä¸Šä¼ çº¸è´§æ°´å•", 
        type=['xlsx', 'csv', 'xls'],
        help="æ”¯æŒ CSV æˆ– Excel æ ¼å¼çš„çº¸è´§äº¤æ˜“æ•°æ®"
    )
    
    phys_file = st.file_uploader(
        "ğŸ“¦ ä¸Šä¼ å®è´§å°è´¦", 
        type=['xlsx', 'csv', 'xls'],
        help="æ”¯æŒ CSV æˆ– Excel æ ¼å¼çš„å®è´§æ•°æ®"
    )
    
    st.markdown("---")
    
    # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
    if ticket_file:
        file_type = detect_file_type(ticket_file.getvalue(), ticket_file.name)
        st.info(f"ğŸ“„ çº¸è´§æ–‡ä»¶: {ticket_file.name} ({file_type.upper()}, {ticket_file.size:,} bytes)")
    
    if phys_file:
        file_type = detect_file_type(phys_file.getvalue(), phys_file.name)
        st.info(f"ğŸ“¦ å®è´§æ–‡ä»¶: {phys_file.name} ({file_type.upper()}, {phys_file.size:,} bytes)")
    
    st.markdown("---")
    
    # åˆ†æé€‰é¡¹
    st.subheader("âš™ï¸ åˆ†æé€‰é¡¹")
    show_detailed_logs = st.checkbox("æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—", value=True)
    
    st.markdown("---")
    
    run_btn = st.button(
        "ğŸš€ å¼€å§‹å…¨æ™¯åˆ†æ", 
        type="primary", 
        use_container_width=True,
        disabled=not (ticket_file and phys_file)
    )
    
    if not (ticket_file and phys_file):
        st.warning("è¯·å…ˆä¸Šä¼ ä¸¤ä¸ªæ–‡ä»¶")
    
    st.caption("Engine: v19 Logic with FIFO Netting")

# ==============================================================================
# ä¸»å†…å®¹åŒºåŸŸ
# ==============================================================================

if run_btn and ticket_file and phys_file:
    with st.spinner('æ­£åœ¨æ‰§è¡ŒåŒ¹é…è¿ç®—...'):
        try:
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # æ­¥éª¤1: å‡†å¤‡æ•°æ®
            status_text.text("æ­¥éª¤ 1/3: å‡†å¤‡æ•°æ®æ–‡ä»¶...")
            progress_bar.progress(20)
            
            # è·å–æ–‡ä»¶å†…å®¹
            paper_content = ticket_file.getvalue()
            paper_name = ticket_file.name
            phys_content = phys_file.getvalue()
            phys_name = phys_file.name
            
            # æ­¥éª¤2: è¿è¡Œå¼•æ“
            status_text.text("æ­¥éª¤ 2/3: æ‰§è¡Œå¥—ä¿åŒ¹é…å¼•æ“...")
            progress_bar.progress(50)
            
            start_t = time.time()
            
            # ç›´æ¥è¿è¡Œå¼•æ“
            df_rels, df_ph_final, df_p_final = run_hedge_engine_directly(
                paper_content, paper_name, phys_content, phys_name
            )
            
            calc_time = time.time() - start_t
            
            # æ­¥éª¤3: æ˜¾ç¤ºç»“æœ
            status_text.text("æ­¥éª¤ 3/3: ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
            progress_bar.progress(90)
            
            progress_bar.progress(100)
            status_text.text("âœ… åˆ†æå®Œæˆï¼")
            
            st.markdown(f'<div class="success-message">åˆ†æå®Œæˆï¼è€—æ—¶ {calc_time:.2f} ç§’</div>', unsafe_allow_html=True)
            
            # --- æ˜¾ç¤ºç»“æœ ---
            st.markdown("## ğŸ“Š åˆ†æç»“æœæ‘˜è¦")
            
            if not df_rels.empty:
                st.success(f"âœ… æˆåŠŸåŒ¹é… {len(df_rels)} ç¬”äº¤æ˜“")
                
                # æ˜¾ç¤ºå…³é”®æŒ‡æ ‡
                if 'Allocated_Vol' in df_rels.columns:
                    total_allocated = df_rels['Allocated_Vol'].abs().sum()
                    
                    # è®¡ç®—å®è´§æ€»æ•å£
                    if 'Volume' in df_ph_final.columns:
                        total_exposure = df_ph_final['Volume'].abs().sum()
                        coverage_rate = (total_allocated / total_exposure * 100) if total_exposure > 0 else 0
                    else:
                        total_exposure = 0
                        coverage_rate = 0
                    
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.metric("å®è´§æ€»æ•å£", f"{total_exposure:,.0f} BBL")
                    
                    with col2:
                        st.metric("å¥—ä¿è¦†ç›–ç‡", f"{coverage_rate:.1f}%", f"{total_allocated:,.0f} BBL")
                    
                    with col3:
                        if 'Alloc_Unrealized_MTM' in df_rels.columns:
                            total_mtm = df_rels['Alloc_Unrealized_MTM'].sum()
                            st.metric("å¥—ä¿ç»„åˆ MTM", f"${total_mtm:,.0f}")
                    
                    with col4:
                        if 'Alloc_Total_PL' in df_rels.columns:
                            total_pl = df_rels['Alloc_Total_PL'].sum()
                            st.metric("å¥—ä¿ç»„åˆ P/L", f"${total_pl:,.0f}")
                
                # æ˜¾ç¤ºåŒ¹é…ç»“æœ
                st.markdown("### ğŸ“‹ åŒ¹é…æ˜ç»†")
                st.dataframe(df_rels, use_container_width=True)
                
                # ä¸‹è½½æŒ‰é’®
                csv = df_rels.to_csv(index=False).encode('utf-8')
                st.download_button(
                    "ğŸ“¥ ä¸‹è½½åŒ¹é…æ˜ç»† CSV",
                    data=csv,
                    file_name="hedge_allocation_details.csv",
                    mime="text/csv",
                    use_container_width=True
                )
                
                # æ˜¾ç¤ºåŒ¹é…ç»Ÿè®¡
                st.markdown("### ğŸ“ˆ åŒ¹é…ç»Ÿè®¡")
                
                tab1, tab2, tab3 = st.tabs(["æŒ‰å“ç§", "æŒ‰æœˆä»½", "æŒ‰æ—¥æœŸ"])
                
                with tab1:
                    if 'Proxy' in df_rels.columns:
                        proxy_summary = df_rels.groupby('Proxy')['Allocated_Vol'].agg(['sum', 'count']).reset_index()
                        proxy_summary.columns = ['å“ç§', 'åŒ¹é…é‡', 'åŒ¹é…ç¬”æ•°']
                        proxy_summary = proxy_summary.sort_values('åŒ¹é…é‡', ascending=False)
                        
                        fig = px.bar(proxy_summary, x='å“ç§', y='åŒ¹é…é‡', 
                                    title="å„å“ç§åŒ¹é…é‡", color='å“ç§')
                        st.plotly_chart(fig, use_container_width=True)
                
                with tab2:
                    if 'Month' in df_rels.columns:
                        month_summary = df_rels.groupby('Month')['Allocated_Vol'].agg(['sum', 'count']).reset_index()
                        month_summary.columns = ['åˆçº¦æœˆ', 'åŒ¹é…é‡', 'åŒ¹é…ç¬”æ•°']
                        month_summary = month_summary.sort_values('åˆçº¦æœˆ')
                        
                        fig = px.bar(month_summary, x='åˆçº¦æœˆ', y='åŒ¹é…é‡', 
                                    title="å„åˆçº¦æœˆåŒ¹é…é‡", color='åˆçº¦æœˆ')
                        st.plotly_chart(fig, use_container_width=True)
                
                with tab3:
                    if 'Open_Date' in df_rels.columns:
                        # æŒ‰æ—¥æœŸç»Ÿè®¡
                        df_rels['Open_Date'] = pd.to_datetime(df_rels['Open_Date'])
                        date_summary = df_rels.groupby(df_rels['Open_Date'].dt.date)['Allocated_Vol'].sum().reset_index()
                        date_summary.columns = ['æ—¥æœŸ', 'åŒ¹é…é‡']
                        date_summary = date_summary.sort_values('æ—¥æœŸ')
                        
                        fig = px.line(date_summary, x='æ—¥æœŸ', y='åŒ¹é…é‡', 
                                     title="æ¯æ—¥åŒ¹é…é‡è¶‹åŠ¿", markers=True)
                        st.plotly_chart(fig, use_container_width=True)
                
            else:
                st.warning("âš ï¸ æœªæ‰¾åˆ°åŒ¹é…ç»“æœ")
                
                # æ˜¾ç¤ºæ•°æ®è¯Šæ–­
                st.markdown("## ğŸ” æ•°æ®è¯Šæ–­")
                
                # è¯»å–åŸå§‹æ•°æ®ç”¨äºè¯Šæ–­
                df_paper_original = read_file_with_correct_type(paper_content, paper_name)
                df_phys_original = read_file_with_correct_type(phys_content, phys_name)
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.subheader("ğŸ“„ çº¸è´§æ•°æ®")
                    st.write(f"æ•°æ®å½¢çŠ¶: {df_paper_original.shape}")
                    
                    # æ£€æŸ¥å…³é”®åˆ—
                    required_paper_cols = ['Trade Date', 'Commodity', 'Month', 'Volume']
                    missing_paper = [col for col in required_paper_cols if col not in df_paper_original.columns]
                    
                    if missing_paper:
                        st.error(f"ç¼ºå¤±åˆ—: {missing_paper}")
                    else:
                        st.success("âœ“ å…³é”®åˆ—å®Œæ•´")
                        
                        # æ˜¾ç¤ºæ•°æ®æ‘˜è¦
                        st.write("æ•°æ®æ‘˜è¦:")
                        summary_data = {
                            'æŒ‡æ ‡': ['æ€»äº¤æ˜“æ•°', 'æ€»äº¤æ˜“é‡', 'å“ç§æ•°', 'åˆçº¦æœˆæ•°'],
                            'æ•°å€¼': [
                                len(df_paper_original),
                                f"{df_paper_original['Volume'].sum():,.0f}",
                                df_paper_original['Commodity'].nunique(),
                                df_paper_original['Month'].nunique()
                            ]
                        }
                        st.table(pd.DataFrame(summary_data))
                
                with col2:
                    st.subheader("ğŸ“¦ å®è´§æ•°æ®")
                    st.write(f"æ•°æ®å½¢çŠ¶: {df_phys_original.shape}")
                    
                    # æ£€æŸ¥å…³é”®åˆ—
                    required_phys_cols = ['Cargo_ID', 'Volume', 'Hedge_Proxy', 'Target_Contract_Month']
                    missing_phys = [col for col in required_phys_cols if col not in df_phys_original.columns]
                    
                    if missing_phys:
                        st.error(f"ç¼ºå¤±åˆ—: {missing_phys}")
                        
                        # æ˜¾ç¤ºå¯ç”¨åˆ—
                        st.write("å¯ç”¨åˆ—:")
                        st.write(list(df_phys_original.columns))
                    else:
                        st.success("âœ“ å…³é”®åˆ—å®Œæ•´")
                        
                        # æ˜¾ç¤ºæ•°æ®æ‘˜è¦
                        st.write("æ•°æ®æ‘˜è¦:")
                        summary_data = {
                            'æŒ‡æ ‡': ['å®è´§ç¬”æ•°', 'æ€»æ•å£', 'å¯¹å†²å“ç§æ•°', 'ç›®æ ‡åˆçº¦æœˆæ•°'],
                            'æ•°å€¼': [
                                len(df_phys_original),
                                f"{df_phys_original['Volume'].sum():,.0f}",
                                df_phys_original['Hedge_Proxy'].nunique(),
                                df_phys_original['Target_Contract_Month'].nunique()
                            ]
                        }
                        st.table(pd.DataFrame(summary_data))
                
                # åŒ¹é…è¯Šæ–­
                st.markdown("### ğŸ”§ åŒ¹é…è¯Šæ–­")
                
                if 'Commodity' in df_paper_original.columns and 'Hedge_Proxy' in df_phys_original.columns:
                    paper_commodities = set(df_paper_original['Commodity'].astype(str).str.upper().str.strip().unique())
                    phys_proxies = set(df_phys_original['Hedge_Proxy'].astype(str).str.upper().str.strip().unique())
                    
                    common = paper_commodities.intersection(phys_proxies)
                    
                    if common:
                        st.success(f"âœ“ æ‰¾åˆ° {len(common)} ä¸ªå…±åŒå“ç§: {list(common)[:5]}")
                    else:
                        st.error(f"âœ— æ²¡æœ‰å…±åŒå“ç§ï¼çº¸è´§å“ç§: {list(paper_commodities)[:5]}ï¼Œå®è´§å“ç§: {list(phys_proxies)[:5]}")
                
                if 'Month' in df_paper_original.columns and 'Target_Contract_Month' in df_phys_original.columns:
                    paper_months = set(df_paper_original['Month'].astype(str).str.upper().str.strip().unique())
                    phys_months = set(df_phys_original['Target_Contract_Month'].astype(str).str.upper().str.strip().unique())
                    
                    common_months = paper_months.intersection(phys_months)
                    
                    if common_months:
                        st.success(f"âœ“ æ‰¾åˆ° {len(common_months)} ä¸ªå…±åŒåˆçº¦æœˆ: {list(common_months)[:5]}")
                    else:
                        st.error(f"âœ— æ²¡æœ‰å…±åŒåˆçº¦æœˆï¼")
            
            # --- æ˜¾ç¤ºå‰©ä½™æ•°æ® ---
            st.markdown("## ğŸ“Š å‰©ä½™æ•å£åˆ†æ")
            
            tab_phy, tab_paper = st.tabs(["å®è´§å‰©ä½™", "çº¸è´§å‰©ä½™"])
            
            with tab_phy:
                if not df_ph_final.empty and 'Unhedged_Volume' in df_ph_final.columns:
                    remaining_phy = df_ph_final[abs(df_ph_final['Unhedged_Volume']) > 0.1].copy()
                    
                    if not remaining_phy.empty:
                        st.info(f"è¿˜æœ‰ {len(remaining_phy)} ç¬”å®è´§å­˜åœ¨æœªå¯¹å†²æ•å£")
                        
                        # è®¡ç®—å‰©ä½™æ•å£
                        total_remaining = remaining_phy['Unhedged_Volume'].abs().sum()
                        st.metric("æ€»å‰©ä½™æ•å£", f"{total_remaining:,.0f} BBL")
                        
                        # æ˜¾ç¤ºå‰©ä½™å®è´§
                        display_cols = ['Cargo_ID', 'Volume', 'Unhedged_Volume', 'Hedge_Proxy', 'Target_Contract_Month']
                        available_cols = [col for col in display_cols if col in remaining_phy.columns]
                        
                        if available_cols:
                            st.dataframe(remaining_phy[available_cols], use_container_width=True)
                    else:
                        st.success("ğŸ‰ æ‰€æœ‰å®è´§æ•å£å‡å·²å®Œå…¨å¯¹å†²ï¼")
                else:
                    st.info("æ— å®è´§å‰©ä½™æ•°æ®")
            
            with tab_paper:
                if not df_p_final.empty and 'Allocated_To_Phy' in df_p_final.columns:
                    # è®¡ç®—å‰©ä½™é‡
                    df_p_final['Remaining'] = df_p_final['Volume'] - df_p_final['Allocated_To_Phy']
                    remaining_paper = df_p_final[abs(df_p_final['Remaining']) > 0.1].copy()
                    
                    if not remaining_paper.empty:
                        st.info(f"è¿˜æœ‰ {len(remaining_paper)} ç¬”çº¸è´§äº¤æ˜“æœªå®Œå…¨åˆ†é…")
                        
                        # è®¡ç®—å‰©ä½™çº¸è´§
                        total_remaining = remaining_paper['Remaining'].abs().sum()
                        st.metric("æ€»å‰©ä½™çº¸è´§", f"{total_remaining:,.0f} BBL")
                        
                        # æ˜¾ç¤ºå‰©ä½™çº¸è´§
                        display_cols = ['Recap No', 'Std_Commodity', 'Month', 'Volume', 'Allocated_To_Phy', 'Remaining']
                        available_cols = [col for col in display_cols if col in remaining_paper.columns]
                        
                        if available_cols:
                            st.dataframe(remaining_paper[available_cols], use_container_width=True)
                    else:
                        st.success("ğŸ“Š æ‰€æœ‰çº¸è´§äº¤æ˜“å‡å·²å®Œå…¨åˆ†é…ï¼")
                else:
                    st.info("æ— çº¸è´§å‰©ä½™æ•°æ®")
                
        except Exception as e:
            st.error(f"âŒ è¿è¡Œæ—¶é”™è¯¯: {str(e)}")
            st.markdown('<div class="error-message">é”™è¯¯è¯¦æƒ…:</div>', unsafe_allow_html=True)
            import traceback
            st.code(traceback.format_exc())
            
            st.info("ğŸ’¡ è°ƒè¯•å»ºè®®:")
            st.markdown("""
            1. æ£€æŸ¥ä¸Šä¼ æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®
            2. ç¡®ä¿æ–‡ä»¶åŒ…å«å¼•æ“éœ€è¦çš„åˆ—å
            3. æ£€æŸ¥æ•°æ®ä¸­æ˜¯å¦æœ‰ç©ºå€¼æˆ–æ ¼å¼é”™è¯¯
            4. æ£€æŸ¥æ–‡ä»¶ç¼–ç 
            """)
else:
    # æ˜¾ç¤ºæ¬¢è¿ç•Œé¢
    st.markdown("""
    ## ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ Hedge Master Analytics
    
    è¿™æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¥—ä¿åŒ¹é…ä¸åˆ†æå¹³å°ï¼ŒåŸºäºå…ˆè¿›çš„ v19 å¼•æ“ç®—æ³•ã€‚
    
    ### ğŸš€ å¿«é€Ÿå¼€å§‹
    
    1. **ä¸Šä¼ æ•°æ®**: åœ¨å·¦ä¾§è¾¹æ ä¸Šä¼ çº¸è´§æ°´å•å’Œå®è´§å°è´¦
    2. **å¼€å§‹åˆ†æ**: ç‚¹å‡»"å¼€å§‹å…¨æ™¯åˆ†æ"æŒ‰é’®
    3. **æŸ¥çœ‹ç»“æœ**: ç³»ç»Ÿå°†è‡ªåŠ¨è®¡ç®—å¹¶å±•ç¤ºå¥—ä¿åŒ¹é…ç»“æœ
    
    ### ğŸ“ æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
    
    - **çº¸è´§æ°´å•**: CSV, Excel (.xlsx, .xls)
    - **å®è´§å°è´¦**: CSV, Excel (.xlsx, .xls)
    
    ### ğŸ”§ æ ¸å¿ƒåŠŸèƒ½
    
    - **æ™ºèƒ½åŒ¹é…**: ä½¿ç”¨å¼€æ”¾å¼æ—¶é—´æ’åºç®—æ³•
    - **FIFOå‡€ä»“**: è‡ªåŠ¨è®¡ç®—çº¸è´§å†…éƒ¨å¯¹å†²
    - **å¯è§†åŒ–åˆ†æ**: ä¸°å¯Œçš„å›¾è¡¨å±•ç¤º
    - **é£é™©ç›‘æ§**: å®æ—¶MTMä¼°å€¼å’Œæ•å£åˆ†æ
    
    ### ğŸ“Š è¾“å‡ºç»“æœ
    
    - è¯¦ç»†çš„å¥—ä¿åŒ¹é…æ˜ç»†
    - å‰©ä½™æ•å£åˆ†æ
    - å¥—ä¿æœ‰æ•ˆæ€§è¯„ä¼°
    - å¯ä¸‹è½½çš„æŠ¥å‘Šå’Œæ•°æ®
    
    ---
    
    **ğŸ“Œ é‡è¦æç¤º**: 
    
    ä¸ºäº†ç¡®ä¿åŒ¹é…æˆåŠŸï¼Œè¯·ç¡®è®¤æ‚¨çš„æ•°æ®æ–‡ä»¶åŒ…å«ä»¥ä¸‹åˆ—ï¼š
    
    **çº¸è´§æ–‡ä»¶å¿…é¡»åŒ…å«**:
    - `Trade Date`: äº¤æ˜“æ—¥æœŸ
    - `Commodity`: å“ç§ï¼ˆå¦‚ BRENT, WTIï¼‰
    - `Month`: åˆçº¦æœˆä»½
    - `Volume`: äº¤æ˜“æ•°é‡
    - `Price`: ä»·æ ¼
    
    **å®è´§æ–‡ä»¶å¿…é¡»åŒ…å«**:
    - `Cargo_ID`: å®è´§ç¼–å·
    - `Volume`: å®è´§æ•°é‡
    - `Hedge_Proxy`: å¯¹å†²å“ç§ï¼ˆå¦‚ BRENT, WTIï¼‰
    - `Target_Contract_Month`: ç›®æ ‡åˆçº¦æœˆä»½
    
    ---
    
    **ğŸ”„ å¦‚æœåŒ¹é…å¤±è´¥**:
    
    å¦‚æœåˆ†æåæ²¡æœ‰åŒ¹é…ç»“æœï¼Œè¯·æ£€æŸ¥:
    1. å“ç§åç§°æ˜¯å¦ä¸€è‡´ï¼ˆå¤§å°å†™æ•æ„Ÿï¼‰
    2. åˆçº¦æœˆä»½æ ¼å¼æ˜¯å¦æ­£ç¡®
    3. æ•°æ®ä¸­æ˜¯å¦æœ‰ç©ºå€¼
    4. åˆ—åæ˜¯å¦æ­£ç¡®
    """)
    
    # æ˜¾ç¤ºç¤ºä¾‹æ•°æ®ç»“æ„
    with st.expander("ğŸ“‹ æŸ¥çœ‹ç¤ºä¾‹æ•°æ®ç»“æ„"):
        col_ex1, col_ex2 = st.columns(2)
        
        with col_ex1:
            st.markdown("**çº¸è´§æ•°æ®ç¤ºä¾‹:**")
            st.code("""
Recap No,Trade Date,Commodity,Month,Volume,Price
T001,2024-01-15,BRENT,JAN 24,10000,85.50
T002,2024-01-16,WTI,JAN 24,5000,82.30
T003,2024-01-17,BRENT,FEB 24,8000,86.20
            """)
        
        with col_ex2:
            st.markdown("**å®è´§æ•°æ®ç¤ºä¾‹:**")
            st.code("""
Cargo_ID,Volume,Direction,Hedge_Proxy,Target_Contract_Month,Designation_Date
C001,5000,Buy,BRENT,JAN 24,2024-01-10
C002,3000,Sell,WTI,JAN 24,2024-01-12
C003,7000,Buy,BRENT,FEB 24,2024-01-15
            """)

# é¡µè„š
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666; font-size: 0.9em;">
    <p>Hedge Master Analytics v2.0 | åŸºäº v19 å¥—ä¿å¼•æ“ | ä¸“ä¸šå¥—ä¿ç®¡ç†å·¥å…·</p>
    <p>Â© 2024 ç‰ˆæƒæ‰€æœ‰ | ä»…ä¾›å†…éƒ¨ä½¿ç”¨</p>
</div>
""", unsafe_allow_html=True)
