import streamlit as st
import pandas as pd
import numpy as np
import io
import time
import warnings
from datetime import datetime
from collections import deque
import plotly.express as px
import plotly.graph_objects as go

warnings.filterwarnings("ignore", category=UserWarning)

# ---------------------------------------------------------
# 1. åŸºç¡€å·¥å…· (Utils)
# ---------------------------------------------------------

def clean_str(series):
    """æ¸…æ´—å­—ç¬¦ä¸²ï¼šå»é™¤å‰åç©ºæ ¼ï¼Œè½¬å¤§å†™ï¼Œæ›¿æ¢ 'NAN' ä¸º''ã€‚"""
    return series.astype(str).str.strip().str.upper().replace('NAN', '')

def standardize_month_vectorized(series):
    """å°†å­—ç¬¦ä¸²æœˆä»½æ ‡å‡†åŒ–ä¸ºç»Ÿä¸€çš„ `MON YY` æ ¼å¼ï¼ˆä¾‹å¦‚ 'JAN 24'ï¼‰ã€‚"""
    s = series.astype(str).str.strip().str.upper()
    s = s.str.replace('-', ' ', regex=False).str.replace('/', ' ', regex=False)
    # é¦–å…ˆå°è¯•ç›´æ¥è§£æ
    dates = pd.to_datetime(s, errors='coerce')
    # æå–æ­£å¸¸è§£æçš„ç»“æœ
    result = dates.dt.strftime('%b %y').str.upper()
    # å¤„ç†æ— æ³•è§£æçš„æƒ…å†µ
    mask_invalid = dates.isna()
    if mask_invalid.any():
        invalid = s[mask_invalid]
        # å°è¯•åŒ¹é…åè½¬å½¢å¼ï¼Œä¾‹å¦‚ '26 APR' -> 'APR 26'
        import re
        def swap_if_match(val):
            m = re.match(r'^(\d{2})\s*([A-Z]{3})$', val)
            if m:
                yr, mon = m.groups()
                return f"{mon} {yr}"
            return val
        swapped = invalid.map(swap_if_match)
        # å°è¯•å†æ¬¡è§£æ
        swapped_dates = pd.to_datetime(swapped, errors='coerce')
        # æ ¼å¼åŒ–
        swapped_formatted = swapped_dates.dt.strftime('%b %y').str.upper()
        # å¯¹æˆåŠŸè§£æçš„éƒ¨åˆ†ç”¨æ–°å€¼
        result.loc[mask_invalid & swapped_dates.notna()] = swapped_formatted.loc[
            swapped_dates.notna()
        ]
        # å¯¹ä»ç„¶æ— æ³•è§£æçš„éƒ¨åˆ†ä¿æŒåŸæ ·
        result.loc[mask_invalid & swapped_dates.isna()] = swapped.loc[
            swapped_dates.isna()
        ]
    return result

# ---------------------------------------------------------
# 2. æ ¸å¿ƒï¼šFIFO å‡€ä»“è®¡ç®—å¼•æ“ (Corrected Netting Engine)
# ---------------------------------------------------------

def calculate_net_positions_corrected(df_paper):
    """ä¿®æ­£åçš„ FIFO å‡€ä»“å¼•æ“ï¼šå†…éƒ¨å¼€ä»“å’Œå¹³ä»“æŠµæ¶ˆã€‚"""
    start_time = time.time()
    st.info("æ‰§è¡Œçº¸è´§å†…éƒ¨å¯¹å†² (FIFO Netting)...")
    progress_bar = st.progress(0)
    
    # æŒ‰äº¤æ˜“æ—¥æœŸæ’åºï¼Œç¡®ä¿ FIFO
    df_paper = df_paper.sort_values(by='Trade Date').reset_index(drop=True)
    # ç»„åˆé”®ï¼šå“ç§+åˆçº¦æœˆ
    df_paper['Group_Key'] = df_paper['Std_Commodity'] + "_" + df_paper['Month']
    # è½¬å­—å…¸è®°å½•åŠ é€Ÿ
    records = df_paper.to_dict('records')
    groups = {}
    # æŒ‰ç»„åˆé”®åˆ†ç»„äº¤æ˜“
    for i, row in enumerate(records):
        key = row['Group_Key']
        if key not in groups:
            groups[key] = []
        groups[key].append(i)
        if i % 100 == 0:
            progress_bar.progress(min(i / len(records) * 0.5, 0.5))
    
    st.info(f"æ•°æ®åˆ†ç»„å®Œæˆï¼Œå…± {len(groups)} ä¸ªç»„ã€‚")
    
    # éå†æ¯ä¸ªç»„ï¼Œè¿›è¡ŒFIFOå¹³ä»“
    group_count = 0
    for key, indices in groups.items():
        open_queue = deque()
        for idx in indices:
            row = records[idx]
            current_vol = row.get('Volume', 0)
            # åˆå§‹åŒ–å‡€å¼€ä»“é‡å’Œå·²å¹³ä»“é‡
            records[idx]['Net_Open_Vol'] = current_vol
            records[idx]['Closed_Vol'] = 0
            records[idx]['Close_Events'] = []
            if abs(current_vol) < 0.0001:
                continue
            current_sign = 1 if current_vol > 0 else -1
            while open_queue:
                q_idx, q_vol, q_sign = open_queue[0]
                # æ–¹å‘ç›¸åæ‰èƒ½æŠµæ¶ˆ
                if q_sign != current_sign:
                    offset = min(abs(current_vol), abs(q_vol))
                    # æ›´æ–°å½“å‰äº¤æ˜“å’Œé˜Ÿåˆ—äº¤æ˜“çš„å‰©ä½™é‡
                    current_vol -= (current_sign * offset)
                    q_vol -= (q_sign * offset)
                    # è®°å½•å¹³ä»“äº‹ä»¶åˆ°åŸäº¤æ˜“
                    close_event = {
                        'Ref': str(records[idx].get('Recap No', '')),
                        'Date': records[idx].get('Trade Date'),
                        'Vol': offset,
                        'Price': records[idx].get('Price', 0)
                    }
                    records[q_idx]['Close_Events'].append(close_event)
                    records[q_idx]['Closed_Vol'] += offset
                    records[q_idx]['Net_Open_Vol'] = q_vol
                    records[idx]['Closed_Vol'] += offset
                    records[idx]['Net_Open_Vol'] = current_vol
                    if abs(q_vol) < 0.0001:
                        open_queue.popleft()
                    else:
                        open_queue[0] = (q_idx, q_vol, q_sign)
                    if abs(current_vol) < 0.0001:
                        break
                else:
                    break
            # å¦‚æœè¿˜æœ‰æœªæŠµæ¶ˆå‡€é¢ï¼Œå…¥é˜Ÿ
            if abs(current_vol) > 0.0001:
                open_queue.append((idx, current_vol, current_sign))
        group_count += 1
        progress_bar.progress(0.5 + (group_count / len(groups)) * 0.5)
    
    elapsed = time.time() - start_time
    progress_bar.progress(1.0)
    st.success(f"çº¸è´§å†…éƒ¨å¯¹å†²å®Œæˆï¼Œè€—æ—¶ {round(elapsed, 2)} ç§’ã€‚")
    return pd.DataFrame(records)

# ---------------------------------------------------------
# 3. åŒ¹é…é€»è¾‘ (v19 å¼€æ”¾å¼æ—¶é—´æ’åº)
# ---------------------------------------------------------

def format_close_details(events):
    """æ•´ç†å¹³ä»“è·¯å¾„ï¼šè¿”å›å­—ç¬¦ä¸²æè¿°ã€åŠ æƒå¹³ä»“ä»·æ ¼ã€å¹³ä»“é‡ã€‚"""
    if not events:
        return "", 0, 0
    details = []
    total_vol = 0
    total_val = 0
    # æŒ‰æ—¥æœŸæ’åºå¹³ä»“äº‹ä»¶
    sorted_events = sorted(events, key=lambda x: x['Date'] if pd.notna(x['Date']) else pd.Timestamp.min)
    for e in sorted_events:
        d_str = e['Date'].strftime('%Y-%m-%d') if pd.notna(e['Date']) else 'N/A'
        p_str = f"@{e['Price']}" if pd.notna(e['Price']) else ""
        details.append(f"[{d_str} Tkt#{e['Ref']} Vol:{e['Vol']:.0f} {p_str}]")
        if pd.notna(e['Price']):
            total_vol += e['Vol']
            total_val += (e['Vol'] * e['Price'])
    weighted_close_price = (total_val / total_vol) if total_vol > 0 else 0
    return " -> ".join(details), weighted_close_price, total_vol

def auto_match_hedges(physical_df, paper_df):
    """å®è´§åŒ¹é…é€»è¾‘"""
    hedge_relations = []
    st.info("å¼€å§‹å®è´§åŒ¹é…...")
    progress_bar = st.progress(0)
    
    active_paper = paper_df.copy()
    active_paper['Allocated_To_Phy'] = 0.0
    active_paper['_original_index'] = active_paper.index
    
    df_phy = physical_df.copy()
    df_phy['_orig_idx'] = df_phy.index
    
    # æ ¹æ®å®šä»·åŸºå‡†ä¼˜å…ˆçº§å¯¹å®è´§æ’åºï¼šBRENT ä¼˜å…ˆåŒ¹é…
    if 'Pricing_Benchmark' in df_phy.columns:
        def bench_prio(x):
            x_str = str(x).upper()
            return 0 if 'BRENT' in x_str else 1
        df_phy['_priority'] = df_phy['Pricing_Benchmark'].apply(bench_prio)
        df_phy = df_phy.sort_values(by=['_priority', '_orig_idx']).reset_index(drop=True)
        df_phy = df_phy.drop(columns=['_priority'])
    else:
        df_phy = df_phy.reset_index(drop=True)
    
    total_cargos = len(df_phy)
    for idx, (_, cargo) in enumerate(df_phy.iterrows()):
        cargo_id = cargo.get('Cargo_ID')
        phy_vol = cargo.get('Unhedged_Volume', 0)
        if abs(phy_vol) < 0.0001:
            continue
            
        proxy = str(cargo.get('Hedge_Proxy', ''))
        target_month = cargo.get('Target_Contract_Month', None)
        phy_dir = cargo.get('Direction', 'Buy')
        desig_date = cargo.get('Designation_Date', pd.NaT)
        
        # åŸºç¡€ç­›é€‰: å“ç§ã€åˆçº¦æœˆ
        candidates_df = active_paper[
            (active_paper['Std_Commodity'].str.contains(proxy, regex=False)) &
            (active_paper['Month'] == target_month)
        ].copy()
        
        if candidates_df.empty:
            continue
            
        # å¦‚æœæœ‰æŒ‡å®šæ—¥æœŸ, è®¡ç®—æ—¶é—´å·®ç»å¯¹å€¼
        if pd.notna(desig_date) and not candidates_df['Trade Date'].isnull().all():
            candidates_df['Time_Lag_Days'] = (candidates_df['Trade Date'] - desig_date).dt.days
            candidates_df['Abs_Lag'] = candidates_df['Time_Lag_Days'].abs()
            candidates_df = candidates_df.sort_values(by=['Abs_Lag', 'Trade Date'])
        else:
            candidates_df['Time_Lag_Days'] = np.nan
            candidates_df = candidates_df.sort_values(by='Trade Date')
        
        # åˆ†é…
        for _, ticket in candidates_df.iterrows():
            if abs(phy_vol) < 1:
                break
                
            original_index = ticket['_original_index']
            curr_allocated = active_paper.at[original_index, 'Allocated_To_Phy']
            curr_total_vol = ticket.get('Volume', 0)
            avail = curr_total_vol - curr_allocated
            
            if abs(avail) < 0.0001:
                continue
                
            alloc_amt_abs = abs(phy_vol) if abs(avail) >= abs(phy_vol) else abs(avail)
            alloc_amt = np.sign(avail) * alloc_amt_abs
            phy_vol -= alloc_amt_abs
            active_paper.at[original_index, 'Allocated_To_Phy'] += alloc_amt
            
            # è®¡ç®— P/L å’Œ MTM
            open_price = ticket.get('Price', 0)
            mtm_price = ticket.get('Mtm Price', 0)
            total_pl_raw = ticket.get('Total P/L', 0)
            close_events = ticket.get('Close_Events', [])
            close_path_str, avg_close_price, _ = format_close_details(close_events)
            unrealized_mtm = (mtm_price - open_price) * alloc_amt
            ratio = 0
            if abs(ticket.get('Volume', 0)) > 0:
                ratio = abs(alloc_amt) / abs(ticket['Volume'])
            allocated_total_pl = total_pl_raw * ratio
            
            hedge_relations.append({
                'Cargo_ID': cargo_id,
                'Proxy': proxy,
                'Designation_Date': desig_date.strftime('%Y-%m-%d') if pd.notna(desig_date) else '',
                'Open_Date': ticket.get('Trade Date'),
                'Time_Lag': ticket.get('Time_Lag_Days'),
                'Ticket_ID': ticket.get('Recap No'),
                'Month': ticket.get('Month'),
                'Allocated_Vol': alloc_amt,
                'Trade_Volume': ticket.get('Volume', 0),
                'Trade_Net_Open': ticket.get('Net_Open_Vol', 0),
                'Trade_Closed_Vol': ticket.get('Closed_Vol', 0),
                'Open_Price': open_price,
                'MTM_Price': mtm_price,
                'Alloc_Unrealized_MTM': round(unrealized_mtm, 2),
                'Alloc_Total_PL': round(allocated_total_pl, 2),
                'Close_Path_Details': close_path_str,
            })
            
            # æ›´æ–°å®è´§æœªå¯¹å†²é‡
            orig_idx = cargo.get('_orig_idx')
            if orig_idx in physical_df.index:
                physical_df.at[orig_idx, 'Unhedged_Volume'] = phy_vol
        
        progress_bar.progress((idx + 1) / total_cargos)
    
    # å°†åˆ†é…é‡å†™å› paper_df
    cols_to_update = active_paper[['_original_index', 'Allocated_To_Phy']].set_index('_original_index')
    paper_df.update(cols_to_update)
    
    return pd.DataFrame(hedge_relations), physical_df

# ---------------------------------------------------------
# 4. Streamlit ä¸»åº”ç”¨
# ---------------------------------------------------------

def main():
    st.set_page_config(
        page_title="å®çº¸è´§å¥—ä¿åŒ¹é…ç³»ç»Ÿ",
        page_icon="ğŸ“Š",
        layout="wide"
    )
    
    # æ ‡é¢˜å’Œä»‹ç»
    st.title("ğŸ“ˆ å®çº¸è´§å¥—ä¿åŒ¹é…ç³»ç»Ÿ")
    st.markdown("""
    æœ¬ç³»ç»Ÿç”¨äºæ‰§è¡Œå®è´§ä¸çº¸è´§çš„å¥—ä¿åŒ¹é…ï¼Œé‡‡ç”¨ FIFO å†…éƒ¨å¯¹å†²ç®—æ³•å’Œå¼€æ”¾å¼æ—¶é—´æ’åºåŒ¹é…é€»è¾‘ã€‚
    """)
    
    # æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
    st.sidebar.header("ğŸ“ æ•°æ®ä¸Šä¼ ")
    
    paper_file = st.sidebar.file_uploader(
        "ä¸Šä¼ çº¸è´§æ•°æ® (CSV/Excel)",
        type=["csv", "xlsx", "xls"],
        help="åŒ…å« Trade Date, Volume, Commodity, Month, Price ç­‰å­—æ®µ"
    )
    
    physical_file = st.sidebar.file_uploader(
        "ä¸Šä¼ å®è´§æ•°æ® (CSV/Excel)",
        type=["csv", "xlsx", "xls"],
        help="åŒ…å« Cargo_ID, Volume, Hedge_Proxy, Target_Contract_Month, Direction ç­‰å­—æ®µ"
    )
    
    # é…ç½®é€‰é¡¹
    st.sidebar.header("âš™ï¸ é…ç½®é€‰é¡¹")
    show_raw_data = st.sidebar.checkbox("æ˜¾ç¤ºåŸå§‹æ•°æ®", value=False)
    show_analysis = st.sidebar.checkbox("æ˜¾ç¤ºåˆ†æå›¾è¡¨", value=True)
    
    if paper_file is not None and physical_file is not None:
        try:
            # è¯»å–æ•°æ®
            with st.spinner("æ­£åœ¨è¯»å–æ•°æ®..."):
                # è¯»å–çº¸è´§æ•°æ®
                if paper_file.name.endswith(('.xlsx', '.xls')):
                    df_paper = pd.read_excel(paper_file)
                else:
                    df_paper = pd.read_csv(paper_file)
                
                # è¯»å–å®è´§æ•°æ®
                if physical_file.name.endswith(('.xlsx', '.xls')):
                    df_physical = pd.read_excel(physical_file)
                else:
                    df_physical = pd.read_csv(physical_file)
            
            # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
            col1, col2 = st.columns(2)
            with col1:
                st.subheader("ğŸ“„ çº¸è´§æ•°æ®é¢„è§ˆ")
                st.write(f"è®°å½•æ•°: {len(df_paper)}")
                st.dataframe(df_paper.head(), use_container_width=True)
            
            with col2:
                st.subheader("ğŸ“¦ å®è´§æ•°æ®é¢„è§ˆ")
                st.write(f"è®°å½•æ•°: {len(df_physical)}")
                st.dataframe(df_physical.head(), use_container_width=True)
            
            # æ•°æ®å¤„ç†
            with st.spinner("æ­£åœ¨å¤„ç†æ•°æ®..."):
                # çº¸è´§æ•°æ®é¢„å¤„ç†
                if 'Trade Date' in df_paper.columns:
                    df_paper['Trade Date'] = pd.to_datetime(df_paper['Trade Date'])
                if 'Volume' in df_paper.columns:
                    df_paper['Volume'] = pd.to_numeric(df_paper['Volume'], errors='coerce').fillna(0)
                if 'Commodity' in df_paper.columns:
                    df_paper['Std_Commodity'] = clean_str(df_paper['Commodity'])
                if 'Month' in df_paper.columns:
                    df_paper['Month'] = standardize_month_vectorized(df_paper['Month'])
                if 'Recap No' not in df_paper.columns:
                    df_paper['Recap No'] = df_paper.index.astype(str)
                
                # å®è´§æ•°æ®é¢„å¤„ç†
                col_map = {'Target_Pricing_Month': 'Target_Contract_Month', 'Month': 'Target_Contract_Month'}
                df_physical.rename(columns=col_map, inplace=True)
                if 'Volume' in df_physical.columns:
                    df_physical['Volume'] = pd.to_numeric(df_physical['Volume'], errors='coerce').fillna(0)
                    df_physical['Unhedged_Volume'] = df_physical['Volume']
                if 'Hedge_Proxy' in df_physical.columns:
                    df_physical['Hedge_Proxy'] = clean_str(df_physical['Hedge_Proxy'])
                if 'Target_Contract_Month' in df_physical.columns:
                    df_physical['Target_Contract_Month'] = standardize_month_vectorized(df_physical['Target_Contract_Month'])
                
                # æŒ‡å®šæ—¥æœŸå¤„ç†
                if 'Designation_Date' in df_physical.columns:
                    df_physical['Designation_Date'] = pd.to_datetime(df_physical['Designation_Date'], errors='coerce')
                elif 'Pricing_Start' in df_physical.columns:
                    df_physical['Designation_Date'] = pd.to_datetime(df_physical['Pricing_Start'], errors='coerce')
                else:
                    df_physical['Designation_Date'] = pd.NaT
            
            # æ‰§è¡ŒåŒ¹é…
            if st.button("ğŸš€ å¼€å§‹å¥—ä¿åŒ¹é…", type="primary"):
                with st.spinner("æ­£åœ¨æ‰§è¡Œå¥—ä¿åŒ¹é…..."):
                    # 1. çº¸è´§å†…éƒ¨å¯¹å†²
                    df_paper_net = calculate_net_positions_corrected(df_paper)
                    
                    # 2. å®è´§åŒ¹é…
                    df_relations, df_physical_updated = auto_match_hedges(df_physical, df_paper_net)
                    
                    # æ˜¾ç¤ºç»“æœ
                    st.subheader("ğŸ“Š åŒ¹é…ç»“æœæ¦‚è§ˆ")
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        total_matched = df_relations['Allocated_Vol'].abs().sum()
                        total_physical = df_physical['Volume'].abs().sum()
                        match_rate = (total_matched / total_physical * 100) if total_physical > 0 else 0
                        st.metric("åŒ¹é…ç‡", f"{match_rate:.1f}%")
                    
                    with col2:
                        st.metric("åŒ¹é…äº¤æ˜“æ•°", len(df_relations))
                    
                    with col3:
                        total_pl = df_relations['Alloc_Total_PL'].sum()
                        st.metric("æ€»P/L", f"${total_pl:,.2f}")
                    
                    # æ˜¾ç¤ºåŒ¹é…æ˜ç»†
                    st.subheader("ğŸ“‹ åŒ¹é…æ˜ç»†")
                    st.dataframe(df_relations, use_container_width=True)
                    
                    # åˆ†æå›¾è¡¨
                    if show_analysis and not df_relations.empty:
                        st.subheader("ğŸ“ˆ åˆ†æå›¾è¡¨")
                        
                        tab1, tab2, tab3 = st.tabs(["åŒ¹é…é‡åˆ†å¸ƒ", "P/Låˆ†å¸ƒ", "æ—¶é—´å·®åˆ†æ"])
                        
                        with tab1:
                            # æŒ‰Cargo_IDçš„åŒ¹é…é‡
                            cargo_summary = df_relations.groupby('Cargo_ID', as_index=False).agg(
                                Allocated_Vol=('Allocated_Vol', lambda series: series.abs().sum())
                            )
                            fig1 = px.bar(cargo_summary, x='Cargo_ID', y='Allocated_Vol',
                                         title='å„Cargo_IDåŒ¹é…é‡',
                                         labels={'Allocated_Vol': 'åŒ¹é…é‡', 'Cargo_ID': 'Cargo ID'})
                            st.plotly_chart(fig1, use_container_width=True)
                        
                        with tab2:
                            # P/Låˆ†å¸ƒ
                            fig2 = px.histogram(df_relations, x='Alloc_Total_PL',
                                               title='P/Låˆ†å¸ƒç›´æ–¹å›¾',
                                               labels={'Alloc_Total_PL': 'P/Lå€¼'})
                            st.plotly_chart(fig2, use_container_width=True)
                        
                        with tab3:
                            # æ—¶é—´å·®åˆ†æ
                            if 'Time_Lag' in df_relations.columns:
                                time_lag_data = df_relations['Time_Lag'].dropna()
                                if not time_lag_data.empty:
                                    fig3 = px.histogram(time_lag_data,
                                                       title='åŒ¹é…æ—¶é—´å·®åˆ†å¸ƒ',
                                                       labels={'value': 'æ—¶é—´å·®(å¤©)'})
                                    st.plotly_chart(fig3, use_container_width=True)
                    
                    # ä¸‹è½½ç»“æœ
                    st.subheader("ğŸ’¾ ä¸‹è½½ç»“æœ")
                    csv = df_relations.to_csv(index=False).encode('utf-8')
                    st.download_button(
                        label="ä¸‹è½½åŒ¹é…ç»“æœCSV",
                        data=csv,
                        file_name="hedge_matching_results.csv",
                        mime="text/csv"
                    )
                    
                    # æ˜¾ç¤ºåŸå§‹æ•°æ®ï¼ˆå¦‚æœé€‰æ‹©ï¼‰
                    if show_raw_data:
                        with st.expander("æŸ¥çœ‹å¤„ç†åæ•°æ®"):
                            col1, col2 = st.columns(2)
                            with col1:
                                st.write("çº¸è´§æ•°æ®ï¼ˆå¤„ç†åï¼‰")
                                st.dataframe(df_paper_net.head(20), use_container_width=True)
                            with col2:
                                st.write("å®è´§æ•°æ®ï¼ˆæ›´æ–°åï¼‰")
                                st.dataframe(df_physical_updated.head(20), use_container_width=True)
        
        except Exception as e:
            st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            st.exception(e)
    
    else:
        # æ˜¾ç¤ºä½¿ç”¨è¯´æ˜
        st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§ä¸Šä¼ çº¸è´§å’Œå®è´§æ•°æ®æ–‡ä»¶å¼€å§‹åŒ¹é…")
        
        with st.expander("ğŸ“– ä½¿ç”¨è¯´æ˜"):
            st.markdown("""
            ### æ•°æ®æ ¼å¼è¦æ±‚
            
            #### çº¸è´§æ•°æ®ï¼ˆå¿…å¡«å­—æ®µï¼‰:
            - **Trade Date**: äº¤æ˜“æ—¥æœŸ
            - **Volume**: äº¤æ˜“é‡ï¼ˆæ­£æ•°è¡¨ç¤ºä¹°å…¥ï¼Œè´Ÿæ•°è¡¨ç¤ºå–å‡ºï¼‰
            - **Commodity**: å•†å“å“ç§
            - **Month**: åˆçº¦æœˆä»½
            - **Price**: ä»·æ ¼
            
            #### å®è´§æ•°æ®ï¼ˆå¿…å¡«å­—æ®µï¼‰:
            - **Cargo_ID**: å®è´§ç¼–å·
            - **Volume**: å®è´§é‡
            - **Hedge_Proxy**: å¥—ä¿ä»£ç†ï¼ˆä¸çº¸è´§CommodityåŒ¹é…ï¼‰
            - **Target_Contract_Month**: ç›®æ ‡åˆçº¦æœˆä»½
            - **Direction**: æ–¹å‘ï¼ˆBuy/Sellï¼‰
            
            ### åŒ¹é…ç®—æ³•è¯´æ˜
            
            1. **å†…éƒ¨å¯¹å†²**: å…ˆå¯¹çº¸è´§è¿›è¡ŒFIFOå†…éƒ¨å¯¹å†²ï¼Œå‡å°‘å†—ä½™å¤´å¯¸
            2. **æ—¶é—´ä¼˜å…ˆåŒ¹é…**: æ ¹æ®æŒ‡å®šæ—¥æœŸï¼ˆDesignation_Dateï¼‰çš„æ—¶é—´å·®è¿›è¡ŒåŒ¹é…
            3. **BRENTä¼˜å…ˆ**: BRENTåŸºå‡†çš„å®è´§ä¼˜å…ˆåŒ¹é…
            4. **å¼€æ”¾å¼åˆ†é…**: å…è®¸åŒä¸€çº¸è´§äº¤æ˜“åŒ¹é…ç»™å¤šä¸ªå®è´§
            
            ### è¾“å‡ºç»“æœ
            
            - åŒ¹é…æ˜ç»†è¡¨
            - åŒ¹é…ç‡ç»Ÿè®¡
            - P/Låˆ†æ
            - å¯ä¸‹è½½çš„CSVç»“æœæ–‡ä»¶
            """)

if __name__ == "__main__":
    main()
